{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EDqBMS1KBMo2"
   },
   "source": [
    "# **Study Project:** *Transformer model for prediction of grasping movements*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14742,
     "status": "ok",
     "timestamp": 1689784387857,
     "user": {
      "displayName": "Florian PÃ¤tzold",
      "userId": "14560267868897327267"
     },
     "user_tz": -120
    },
    "id": "F7Sn6IstgaA6",
    "outputId": "30cf809f-df17-4146-e0f8-ac624d375c1b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 11:11:23.522115: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.animation import FuncAnimation, FFMpegWriter\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "For video generation download FFMPEG: https://ffmpeg.org/download.html#build-windows\n",
    "'''\n",
    "\n",
    "# Include FFmpeg in the path\n",
    "plt.rcParams['animation.ffmpeg_path'] = r'ffpmeg\\bin\\ffmpeg.exe'  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deserialize(serialized_example):\n",
    "    \"\"\"\n",
    "    Function to deserialize tensors from bytes.\n",
    "    \"\"\"\n",
    "\n",
    "    feature_description = {\n",
    "        'context': tf.io.FixedLenFeature([], tf.string),\n",
    "        'input': tf.io.FixedLenFeature([], tf.string),\n",
    "        'target': tf.io.FixedLenFeature([], tf.string)\n",
    "    }\n",
    "\n",
    "    example = tf.io.parse_single_example(serialized_example, feature_description)\n",
    "    context = tf.io.parse_tensor(example['context'], out_type=tf.float64)\n",
    "    x = tf.io.parse_tensor(example['input'], out_type=tf.float64)\n",
    "    target = tf.io.parse_tensor(example['target'], out_type=tf.float64)\n",
    "\n",
    "    return context, x, target\n",
    "\n",
    "# Load tensorflow dataset\n",
    "train_ds_path = \"./data/train_ds.zip\"\n",
    "test_ds_path = \"./data/test_ds.zip\"\n",
    "\n",
    "# Create a TFRecordDataset from the saved file\n",
    "train_dataset = tf.data.TFRecordDataset(train_ds_path, compression_type='GZIP')\n",
    "test_dataset = tf.data.TFRecordDataset(test_ds_path, compression_type='GZIP')\n",
    "\n",
    "# Deserialize the zipped dataset\n",
    "train_dataset = train_dataset.map(deserialize)\n",
    "test_dataset = test_dataset.map(deserialize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model from zip file\n",
    "model_path = \"./models/transformer\"\n",
    "\n",
    "PAD = -2\n",
    "\n",
    "def compute_mask(inputs, padding_token=0):\n",
    "    return tf.cast(tf.not_equal(inputs, padding_token), tf.float64)\n",
    "\n",
    "# Define custom functions\n",
    "def masked_loss(label, pred, pad_token=-2):\n",
    "    mask = label != pad_token\n",
    "    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "    loss = loss_object(label, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss.dtype)\n",
    "    loss *= mask\n",
    "\n",
    "    loss = tf.reduce_sum(loss)/tf.reduce_sum(mask)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def masked_accuracy(label, pred, pad_token=-2):\n",
    "    pred = tf.argmax(pred, axis=2)\n",
    "    label = tf.cast(label, pred.dtype)\n",
    "    match = label == pred\n",
    "\n",
    "    mask = label != pad_token\n",
    "\n",
    "    match = match & mask\n",
    "\n",
    "    match = tf.cast(match, dtype=tf.float64)\n",
    "    mask = tf.cast(mask, dtype=tf.float64)\n",
    "    return tf.reduce_sum(match)/tf.reduce_sum(mask)\n",
    "\n",
    "tf.keras.utils.get_custom_objects()['masked_loss'] = masked_loss\n",
    "tf.keras.utils.get_custom_objects()['masked_accuracy'] = masked_accuracy\n",
    "\n",
    "# Import the model\n",
    "transformer = tf.keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TOKENS = 100\n",
    "\"\"\"\n",
    "context = bbox_seq\n",
    "input = angle\n",
    "target = target_angle\n",
    "\"\"\"\n",
    "\n",
    "class Predictor(tf.Module):\n",
    "  def __init__(self, transformer):\n",
    "    self.transformer = transformer\n",
    "\n",
    "  def __call__(self, bbox_seq, max_length=MAX_TOKENS):\n",
    "    \n",
    "    # The input needs `[START]` and `[END]` tokens, \n",
    "    # but this is already provided as its taken from the dataset\n",
    "    assert isinstance(bbox_seq, tf.Tensor)\n",
    "    if len(bbox_seq.shape) == 0:\n",
    "      bbox_seq = bbox_seq[tf.newaxis]\n",
    "\n",
    "    encoder_input = bbox_seq\n",
    "\n",
    "    # Set tokens for `[START]` and `[END]` in later steps\n",
    "    start_token = tf.constant([-333], dtype=tf.int64)\n",
    "    end_token = tf.constant([-2], dtype=tf.int64)\n",
    "\n",
    "    # # Try:\n",
    "    \n",
    "    # # Create an empty output array with the shape of the encoder input\n",
    "    # # Fill with padding values and set the first entry to start token\n",
    "\n",
    "    # shape = tf.shape(encoder_input)\n",
    "    # empty_array = np.empty((shape[0],1))\n",
    "    # empty_array.fill(PAD)  \n",
    "    # empty_array[0, 0] = start_token\n",
    "    # output_array = tf.convert_to_tensor(empty_array)\n",
    "\n",
    "    # Add batch dimensions\n",
    "    encoder_input = encoder_input[tf.newaxis, :]\n",
    "\n",
    "    # `tf.TensorArray` is required here (instead of a Python list), so that the\n",
    "    # dynamic-loop can be traced by `tf.function`.\n",
    "    output_array = tf.TensorArray(dtype=tf.int64, size=0, dynamic_size=True)\n",
    "    output_array = output_array.write(0, start_token)\n",
    "\n",
    "    for i in tf.range(max_length):\n",
    "\n",
    "      # What it should be (shape (1,1) in the beginning and growing)\n",
    "      output = tf.transpose(output_array.stack())\n",
    "\n",
    "      # What it needs to be (shape (66, 1) aka. matching the sequence length of the context)\n",
    "      #output = tf.zeros(shape=(66, 1), dtype=tf.float32)\n",
    "\n",
    "      predictions = self.transformer((encoder_input, output[tf.newaxis]), training=False, mask=None)\n",
    "\n",
    "      # # Try:\n",
    "\n",
    "      # mask = compute_mask(output_array)\n",
    "      # predictions = self.transformer((encoder_input, output_array[tf.newaxis]), training=False)#, mask=mask[tf.newaxis])\n",
    "\n",
    "\n",
    "      # Select the last token from the `seq_len` dimension.\n",
    "      predictions = predictions[:, -1:, :]  # Shape `(batch_size, 1, vocab_size)`.\n",
    "\n",
    "      predicted_id = tf.argmax(predictions, axis=-1)\n",
    "\n",
    "      # Concatenate the `predicted_id` to the output which is given to the\n",
    "      # decoder as its input.\n",
    "      output_array = output_array.write(i+1, predicted_id[0])\n",
    "\n",
    "      if predicted_id == end_token:\n",
    "        break\n",
    "\n",
    "    output = tf.transpose(output_array.stack())\n",
    "    # The output shape is `(1, angles)`.\n",
    "    angles = output[0]  # Shape: `()`.\n",
    "\n",
    "    return angles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = Predictor(transformer)\n",
    "\n",
    "def print_prediction(bbox_seq, angles, ground_truth):\n",
    "  #print(f'{\"Input:\":15s}: {bbox_seq}')\n",
    "  print(f'{\"Prediction\"}: {angles.numpy().flatten().tolist()}')\n",
    "  print(f'{\"Ground truth\"}: {ground_truth.numpy().flatten().tolist()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not find matching concrete function to call loaded from the SavedModel. Got:\n  Positional arguments (3 total):\n    * (<tf.Tensor 'inputs:0' shape=(1, 66, 8) dtype=float32>,\n <tf.Tensor 'inputs_1:0' shape=(1, 1, 1) dtype=int64>)\n    * None\n    * False\n  Keyword arguments: {}\n\n Expected these arguments to match one of the following 4 option(s):\n\nOption 1:\n  Positional arguments (3 total):\n    * (TensorSpec(shape=(None, 66, 8), dtype=tf.float32, name='input_1'),\n TensorSpec(shape=(None, 66, 1), dtype=tf.float32, name='input_2'))\n    * None\n    * True\n  Keyword arguments: {}\n\nOption 2:\n  Positional arguments (3 total):\n    * (TensorSpec(shape=(None, 66, 8), dtype=tf.float32, name='input_1'),\n TensorSpec(shape=(None, 66, 1), dtype=tf.float32, name='input_2'))\n    * None\n    * False\n  Keyword arguments: {}\n\nOption 3:\n  Positional arguments (3 total):\n    * (TensorSpec(shape=(None, 66, 8), dtype=tf.float32, name='inputs_0'),\n TensorSpec(shape=(None, 66, 1), dtype=tf.float32, name='inputs_1'))\n    * None\n    * True\n  Keyword arguments: {}\n\nOption 4:\n  Positional arguments (3 total):\n    * (TensorSpec(shape=(None, 66, 8), dtype=tf.float32, name='inputs_0'),\n TensorSpec(shape=(None, 66, 1), dtype=tf.float32, name='inputs_1'))\n    * None\n    * False\n  Keyword arguments: {}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;66;03m# Which sequence to predict\u001b[39;00m\n\u001b[1;32m      5\u001b[0m input_seq \u001b[38;5;241m=\u001b[39m context[i]\n\u001b[0;32m----> 6\u001b[0m angles \u001b[38;5;241m=\u001b[39m \u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_seq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m print_prediction(context[i], angles, target)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[23], line 53\u001b[0m, in \u001b[0;36mPredictor.__call__\u001b[0;34m(self, bbox_seq, max_length)\u001b[0m\n\u001b[1;32m     48\u001b[0m output \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mtranspose(output_array\u001b[38;5;241m.\u001b[39mstack())\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# What it needs to be (shape (66, 1) aka. matching the sequence length of the context)\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m#output = tf.zeros(shape=(66, 1), dtype=tf.float32)\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnewaxis\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# # Try:\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# mask = compute_mask(output_array)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     60\u001b[0m \n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Select the last token from the `seq_len` dimension.\u001b[39;00m\n\u001b[1;32m     62\u001b[0m predictions \u001b[38;5;241m=\u001b[39m predictions[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:, :]  \u001b[38;5;66;03m# Shape `(batch_size, 1, vocab_size)`.\u001b[39;00m\n",
      "File \u001b[0;32m~/Applications/miniconda3/envs/transformer/lib/python3.11/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Applications/miniconda3/envs/transformer/lib/python3.11/site-packages/tensorflow/python/saved_model/function_deserialization.py:295\u001b[0m, in \u001b[0;36mrecreate_function.<locals>.restored_function_body\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m   positional, keyword \u001b[38;5;241m=\u001b[39m concrete_function\u001b[38;5;241m.\u001b[39mstructured_input_signature\n\u001b[1;32m    292\u001b[0m   signature_descriptions\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m    293\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOption \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  Keyword arguments: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    294\u001b[0m           index \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, _pretty_format_positional(positional), keyword))\n\u001b[0;32m--> 295\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find matching concrete function to call loaded from the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSavedModel. Got:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_pretty_format_positional(args)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  Keyword \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marguments: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Expected these arguments to match one of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfollowing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(saved_function\u001b[38;5;241m.\u001b[39mconcrete_functions)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m option(s):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(\u001b[38;5;28mchr\u001b[39m(\u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mchr\u001b[39m(\u001b[38;5;241m10\u001b[39m))\u001b[38;5;241m.\u001b[39mjoin(signature_descriptions)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Could not find matching concrete function to call loaded from the SavedModel. Got:\n  Positional arguments (3 total):\n    * (<tf.Tensor 'inputs:0' shape=(1, 66, 8) dtype=float32>,\n <tf.Tensor 'inputs_1:0' shape=(1, 1, 1) dtype=int64>)\n    * None\n    * False\n  Keyword arguments: {}\n\n Expected these arguments to match one of the following 4 option(s):\n\nOption 1:\n  Positional arguments (3 total):\n    * (TensorSpec(shape=(None, 66, 8), dtype=tf.float32, name='input_1'),\n TensorSpec(shape=(None, 66, 1), dtype=tf.float32, name='input_2'))\n    * None\n    * True\n  Keyword arguments: {}\n\nOption 2:\n  Positional arguments (3 total):\n    * (TensorSpec(shape=(None, 66, 8), dtype=tf.float32, name='input_1'),\n TensorSpec(shape=(None, 66, 1), dtype=tf.float32, name='input_2'))\n    * None\n    * False\n  Keyword arguments: {}\n\nOption 3:\n  Positional arguments (3 total):\n    * (TensorSpec(shape=(None, 66, 8), dtype=tf.float32, name='inputs_0'),\n TensorSpec(shape=(None, 66, 1), dtype=tf.float32, name='inputs_1'))\n    * None\n    * True\n  Keyword arguments: {}\n\nOption 4:\n  Positional arguments (3 total):\n    * (TensorSpec(shape=(None, 66, 8), dtype=tf.float32, name='inputs_0'),\n TensorSpec(shape=(None, 66, 1), dtype=tf.float32, name='inputs_1'))\n    * None\n    * False\n  Keyword arguments: {}"
     ]
    }
   ],
   "source": [
    "for batch, (context, x, target) in enumerate(test_dataset):\n",
    "\n",
    "    i = 0 # Which sequence to predict\n",
    "\n",
    "    input_seq = context[i]\n",
    "    angles = predictor(tf.constant(input_seq))\n",
    "    print_prediction(context[i], angles, target)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth: [105.0, 77.0, 81.0, 80.0, 65.0, 49.0, 70.0, 88.0, 83.0, 79.0, 80.0, 85.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0]\n",
      "Prediction: [345, 48, 103, 35, 35, 103, 103, 103, 103, 355, 355, 355, 355, 266, 317, 23, 1, 23, 23, 23, 23, 23, 1, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 1, 23, 23, 23, 23, 23, 1, 23, 23, 23, 23, 23, 1, 1, 23, 23, 23, 23]\n"
     ]
    }
   ],
   "source": [
    "for batch, (context, x, target) in enumerate(train_dataset):\n",
    "\n",
    "        mask = compute_mask(target, padding_token=PAD)\n",
    "        logits = transformer((context, x), training=False)\n",
    "        predictions = tf.argmax(logits, axis=2)\n",
    "\n",
    "        print(f'{\"Ground Truth\"}: {target[1].numpy().flatten().tolist()}')\n",
    "        print(f'{\"Prediction\"}: {predictions[1].numpy().flatten().tolist()}')\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "QC1eRfTGuWyA",
    "cJf8BcE-to4F",
    "n1OVMgLRiBSf",
    "tHmhuucQ4QVr",
    "r2zT3EQ_4Skf",
    "veRXne1V4-wb",
    "F8o1Fa7R538c"
   ],
   "provenance": [
    {
     "file_id": "https://github.com/keras-team/keras-io/blob/master/examples/timeseries/ipynb/timeseries_classification_transformer.ipynb",
     "timestamp": 1686292503880
    }
   ]
  },
  "kernelspec": {
   "display_name": "studyproject_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
