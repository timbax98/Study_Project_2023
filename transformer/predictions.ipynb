{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EDqBMS1KBMo2"
   },
   "source": [
    "# **Study Project:** *Transformer model for prediction of grasping movements*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14742,
     "status": "ok",
     "timestamp": 1689784387857,
     "user": {
      "displayName": "Florian PÃ¤tzold",
      "userId": "14560267868897327267"
     },
     "user_tz": -120
    },
    "id": "F7Sn6IstgaA6",
    "outputId": "30cf809f-df17-4146-e0f8-ac624d375c1b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-11 13:53:20.984034: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deserialize(serialized_example):\n",
    "    \"\"\"\n",
    "    Function to deserialize tensors from bytes.\n",
    "    \"\"\"\n",
    "\n",
    "    feature_description = {\n",
    "        'context': tf.io.FixedLenFeature([], tf.string),\n",
    "        'input': tf.io.FixedLenFeature([], tf.string),\n",
    "        'target': tf.io.FixedLenFeature([], tf.string)\n",
    "    }\n",
    "\n",
    "    example = tf.io.parse_single_example(serialized_example, feature_description)\n",
    "    context = tf.io.parse_tensor(example['context'], out_type=tf.float64)\n",
    "    x = tf.io.parse_tensor(example['input'], out_type=tf.float64)\n",
    "    target = tf.io.parse_tensor(example['target'], out_type=tf.float64)\n",
    "\n",
    "    return context, x, target\n",
    "\n",
    "\n",
    "def compute_mask(inputs, padding_token=0):\n",
    "    return tf.cast(tf.not_equal(inputs, padding_token), tf.float64)\n",
    "\n",
    "\n",
    "# Define custom functions\n",
    "def masked_loss(label, pred, pad_token=-2):\n",
    "    mask = label != pad_token\n",
    "    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "    loss = loss_object(label, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss.dtype)\n",
    "    loss *= mask\n",
    "\n",
    "    loss = tf.reduce_sum(loss)/tf.reduce_sum(mask)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def masked_accuracy(label, pred, pad_token=-2):\n",
    "    pred = tf.argmax(pred, axis=2)\n",
    "    label = tf.cast(label, pred.dtype)\n",
    "    match = label == pred\n",
    "\n",
    "    mask = label != pad_token\n",
    "\n",
    "    match = match & mask\n",
    "\n",
    "    match = tf.cast(match, dtype=tf.float64)\n",
    "    mask = tf.cast(mask, dtype=tf.float64)\n",
    "    return tf.reduce_sum(match)/tf.reduce_sum(mask)\n",
    "\n",
    "tf.keras.utils.get_custom_objects()['masked_loss'] = masked_loss\n",
    "tf.keras.utils.get_custom_objects()['masked_accuracy'] = masked_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tensorflow dataset\n",
    "train_ds_path = \"./data/train_ds.zip\"\n",
    "test_ds_path = \"./data/test_ds.zip\"\n",
    "\n",
    "# Create a TFRecordDataset from the saved file\n",
    "train_dataset = tf.data.TFRecordDataset(train_ds_path, compression_type='GZIP')\n",
    "test_dataset = tf.data.TFRecordDataset(test_ds_path, compression_type='GZIP')\n",
    "\n",
    "# Deserialize the zipped dataset\n",
    "train_dataset = train_dataset.map(deserialize)\n",
    "test_dataset = test_dataset.map(deserialize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model from zip file\n",
    "model_path = \"./models/transformer\"\n",
    "PAD = -2\n",
    "\n",
    "# Import the model\n",
    "transformer = tf.keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-11 13:53:37.874603: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    }
   ],
   "source": [
    "MAX_SEQ_LEN = max(con.shape[1] for con, x, t in test_dataset) # get maximum sequence length of ds\n",
    "\n",
    "class Predictor(tf.Module):\n",
    "    def __init__(self, transformer):\n",
    "        self.transformer = transformer\n",
    "\n",
    "    def __call__(self, bbox_sequence, max_length):\n",
    "\n",
    "        assert isinstance(bbox_sequence, tf.Tensor)\n",
    "\n",
    "        # For first frame with shape (8) expand dim for (SEQ_LEN, 8)\n",
    "        if len(bbox_sequence.shape) == 1:\n",
    "            bbox_sequence = bbox_sequence[tf.newaxis, :]\n",
    "\n",
    "        # If max_length is longer than current seq_len, just take the seq_len\n",
    "        # -> does not interfere with pad_length down below\n",
    "        max_length = min(len(bbox_sequence), max_length)\n",
    "\n",
    "        # live application is just one continuous sequence, but transformer trained on batches\n",
    "        # -> add batch_size dimension for shape (BS, SEQ_LEN, 8); necessary for inference?\n",
    "        encoder_input = bbox_sequence[tf.newaxis, :, :]\n",
    "\n",
    "        # Input start and output end tokens\n",
    "        start = tf.constant([-333], dtype=tf.int32)\n",
    "        end = tf.constant([-1], dtype=tf.int32)\n",
    "\n",
    "        # `tf.TensorArray` is required here (instead of a Python list), so that the\n",
    "        # dynamic-loop can be traced by `tf.function`.\n",
    "        output_array = tf.TensorArray(dtype=tf.int32, size=0, dynamic_size=True)\n",
    "        output_array = output_array.write(0, start)\n",
    "\n",
    "        for i in tf.range(max_length):\n",
    "            # -> add batch_size dimension necessary for inference?\n",
    "            output = output_array.stack()[tf.newaxis, :, :]\n",
    "\n",
    "            # dynamically pad output\n",
    "            pad_length = len(bbox_sequence) - int(output_array.size())\n",
    "            paddings = tf.constant([[0, 0], [0, pad_length], [0, 0]])\n",
    "            output = tf.pad(output, paddings, \"CONSTANT\")\n",
    "            output = tf.cast(output, tf.float32)\n",
    "            # mask necessary for prediction or only for training?\n",
    "            \n",
    "            predictions = self.transformer(inputs=(encoder_input, output), mask=None, training=False)\n",
    "\n",
    "            # Select the last token from the `seq_len` dimension.\n",
    "            predictions = predictions[:, -1:, :]  # Shape `(batch_size, 1, vocab_size)`.\n",
    "\n",
    "            predicted_id = tf.cast(tf.argmax(predictions, axis=-1), dtype=tf.int32)\n",
    "\n",
    "            # Concatenate the `predicted_id` to the output which is given to the\n",
    "            # decoder as its input.\n",
    "            output_array = output_array.write(i+1, predicted_id[0])\n",
    "\n",
    "            if predicted_id == end:\n",
    "                break\n",
    "\n",
    "        output = output_array.stack()[tf.newaxis, :, :]\n",
    "        output = tf.cast(output, tf.float32)\n",
    "\n",
    "        # `tf.function` prevents us from using the attention_weights that were\n",
    "        # calculated on the last iteration of the loop.\n",
    "        # So, recalculate them outside the loop.\n",
    "        self.transformer(inputs=(encoder_input, output[:, :-1, :]), mask=None, training=False)\n",
    "        #attention_weights = self.transformer.decoder.last_attn_scores\n",
    "\n",
    "        return output #, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0, iteration 0\n",
      "Prediction: [171.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 48.0, 84.0, 84.0, 84.0, 84.0, 84.0, 84.0, 84.0, 84.0, 84.0, 84.0, 84.0, 84.0, 84.0, 48.0]\n",
      "Ground truth: [143.0, 156.0, 104.0, 104.0, 102.0, 95.0, 92.0, 101.0, 43.0, -1.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0]\n",
      "Mean Squared Error: 86559.73\n",
      "\n",
      "Batch 1, iteration 0\n",
      "Prediction: [347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 84.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 84.0, 347.0, 347.0, 347.0, 347.0, 347.0, 84.0, 84.0, 347.0, 347.0, 347.0, 347.0]\n",
      "Ground truth: [22.0, 27.0, 30.0, 32.0, 39.0, 27.0, -1.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0]\n",
      "Mean Squared Error: 112950.7\n",
      "\n",
      "Batch 2, iteration 0\n",
      "Prediction: [347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 84.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 84.0, 347.0, 347.0, 347.0, 84.0, 347.0, 84.0, 347.0, 347.0, 347.0, 84.0, 84.0, 347.0, 347.0, 347.0, 84.0, 347.0, 84.0, 84.0, 84.0, 347.0, 347.0, 347.0, 84.0, 84.0, 84.0, 84.0, 84.0, 84.0]\n",
      "Ground truth: [46.0, 59.0, 95.0, 77.0, 75.0, 34.0, 35.0, -1.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0]\n",
      "Mean Squared Error: 89914.06\n",
      "\n",
      "Batch 3, iteration 0\n",
      "Prediction: [23.0, 23.0, 270.0, 253.0, 331.0, 253.0, 331.0, 331.0, 331.0, 331.0, 331.0, 331.0, 331.0, 331.0, 331.0, 331.0, 331.0, 317.0, 251.0, 356.0, 356.0, 356.0, 331.0, 170.0, 310.0, 310.0, 310.0, 310.0, 310.0, 310.0, 68.0, 68.0, 310.0, 310.0, 310.0, 310.0, 68.0, 310.0, 310.0, 310.0, 310.0, 310.0, 68.0, 310.0, 310.0, 310.0, 310.0, 68.0, 68.0, 68.0, 67.0, 67.0, 67.0, 67.0, 67.0, 67.0, 356.0, 356.0, 356.0, 67.0, 144.0, 253.0, 253.0, 253.0, 253.0, 79.0]\n",
      "Ground truth: [71.0, 34.0, 111.0, 57.0, 79.0, 33.0, 37.0, 36.0, 61.0, 30.0, 43.0, 37.0, 44.0, 41.0, 41.0, 24.0, 28.0, 33.0, 19.0, 25.0, 19.0, 61.0, 29.0, -1.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0]\n",
      "Mean Squared Error: 64783.44\n",
      "\n",
      "Batch 4, iteration 0\n",
      "Prediction: [223.0, 129.0, 129.0, 331.0, 331.0, 331.0, 331.0, 331.0, 331.0, 331.0, 331.0, 331.0, 331.0, 331.0, 331.0, 331.0, 253.0, 331.0, 331.0, 331.0, 331.0, 253.0, 331.0, 251.0, 253.0, 331.0, 331.0, 331.0, 331.0, 251.0, 170.0, 310.0, 310.0, 310.0, 310.0, 310.0, 68.0, 68.0, 310.0, 310.0, 310.0, 68.0, 68.0, 310.0, 310.0, 310.0, 68.0, 68.0, 68.0, 67.0, 317.0, 67.0, 67.0, 67.0, 67.0, 67.0, 67.0, 67.0, 67.0, 67.0, 144.0, 253.0, 253.0, 253.0, 253.0, 79.0]\n",
      "Ground truth: [48.0, 52.0, 51.0, 57.0, 47.0, 50.0, 52.0, 42.0, 34.0, 39.0, 39.0, 20.0, 13.0, 2.0, 16.0, 10.0, 27.0, -1.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0]\n",
      "Mean Squared Error: 61883.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictor = Predictor(transformer)\n",
    "\n",
    "# Iterate through all batches in the DS\n",
    "for batch, (context, x, target) in enumerate(test_dataset):\n",
    "\n",
    "    # Iterate through all sequences (videos) in the batch\n",
    "    for i, seq in enumerate(context):\n",
    "        seq_len = len(seq)\n",
    "        angles = predictor(bbox_sequence=seq, max_length=seq_len)\n",
    "        pred = angles.numpy().flatten().tolist()\n",
    "        pred = pred[1:]\n",
    "        true = target[i].numpy().flatten().tolist()\n",
    "        mse = tf.keras.losses.mean_squared_error(true, pred)\n",
    "\n",
    "        # Print predictions\n",
    "        print(f'Batch {batch}, iteration {i}')\n",
    "        print(f'Prediction: {pred}')\n",
    "        print(f'Ground truth: {true}')\n",
    "        print(\"Mean Squared Error:\", round(mse.numpy(), 2))\n",
    "        print()\n",
    "        break # debugging: print only one sequence in batch"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "QC1eRfTGuWyA",
    "cJf8BcE-to4F",
    "n1OVMgLRiBSf",
    "tHmhuucQ4QVr",
    "r2zT3EQ_4Skf",
    "veRXne1V4-wb",
    "F8o1Fa7R538c"
   ],
   "provenance": [
    {
     "file_id": "https://github.com/keras-team/keras-io/blob/master/examples/timeseries/ipynb/timeseries_classification_transformer.ipynb",
     "timestamp": 1686292503880
    }
   ]
  },
  "kernelspec": {
   "display_name": "studyproject_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
