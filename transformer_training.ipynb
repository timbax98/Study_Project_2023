{"cells":[{"cell_type":"markdown","metadata":{"id":"F27GbtR93QsH"},"source":["# Transformer Training"]},{"cell_type":"markdown","source":["## Import packages"],"metadata":{"id":"QC1eRfTGuWyA"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"NwcqfPRcaSGS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687345722872,"user_tz":-120,"elapsed":2401,"user":{"displayName":"Florian P√§tzold","userId":"14560267868897327267"}},"outputId":"de5a3ce9-d712-4d78-9824-d65cc5b7e379"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["!pip install ultralytics\n","\n","from IPython import display\n","display.clear_output()"],"metadata":{"id":"WGIVjC8sf_HX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Import necessary packages\n","import cv2\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.layers import MultiHeadAttention, LayerNormalization, Dropout\n","import os\n","from tqdm import tqdm\n","import ultralytics\n","ultralytics.checks()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F7Sn6IstgaA6","executionInfo":{"status":"ok","timestamp":1687345747762,"user_tz":-120,"elapsed":20053,"user":{"displayName":"Florian P√§tzold","userId":"14560267868897327267"}},"outputId":"6a3dc47b-d094-4193-d2d4-420898227844"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Ultralytics YOLOv8.0.120 üöÄ Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n","Setup complete ‚úÖ (2 CPUs, 12.7 GB RAM, 24.1/78.2 GB disk)\n"]}]},{"cell_type":"markdown","source":["## Helpers"],"metadata":{"id":"cJf8BcE-to4F"}},{"cell_type":"code","source":["def VideoBBs(videopath):\n","  # Use object tracker to get the bounding boxes and classIDs in a 'results' object\n","  bbs = np.zeros((1, 7))\n","  # It is also possible to pass the whole folder as path,\n","  # but we still want the flexibility to access single videos\n","  results = model.track(source=videopath, tracker=\"bytetrack.yaml\")\n","\n","  # Get class names\n","  classes = results[0].names\n","\n","  # Iterate through each frame of a video to get all bounding boxes for a frame\n","  for frame in range(len(results)):\n","\n","    # x_center, y_center, bbwidth, bbheight of bbs of this frame\n","    xywh = results[frame].boxes.xywh.detach().cpu().numpy()\n","    n = len(xywh) # number of bounding boxes\n","    cls = results[frame].boxes.cls.detach().cpu().numpy().reshape((n,1))\n","    # if the object tracker is currently tracking at least one object, save the trackingID for that object, else fill with -1 placeholder\n","    trackingID = results[frame].boxes.id.detach().cpu().numpy().reshape((n,1)) if results[frame].boxes.is_track else np.repeat(-1, n).reshape((n,1))\n","    frame_count = np.repeat(frame, n).reshape((n,1))\n","\n","    # bind the data together\n","    data = np.concatenate((frame_count, cls, xywh, trackingID), axis=1)\n","    # add all data of this frame to all data of this video\n","    bbs = np.concatenate((bbs, data), axis=0)\n","\n","  return bbs, classes"],"metadata":{"id":"LCgIq5tJPEHX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def Align(videopath, to_path, bounding_boxes, width=1920, height=1120):\n","\n","  ############################ Read video ####################################\n","  cap = cv2.VideoCapture(videopath)\n","  frameCount = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","  frameWidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","  frameHeight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","  FPS = int(cap.get(cv2.CAP_PROP_FPS))\n","\n","  video = np.zeros((frameCount, frameHeight, frameWidth, 3), np.dtype('uint8'))\n","  fc = 0\n","  ret = True\n","\n","  while (fc < frameCount and ret):\n","      ret, video[fc] = cap.read()\n","      fc += 1\n","\n","  cap.release()\n","  ############################################################################\n","\n","\n","  ############################ Correct video #################################\n","  bbs = bounding_boxes\n","  width = width\n","  height = height\n","  center_x = (width/2)\n","  center_y = (height/2)\n","  x_dists = []\n","  y_dists = []\n","\n","  for box_pos in bbs:\n","    if np.isnan(box_pos).any():\n","      # if all values were nan, then 0 would be the max, so the corrected video would be the original video\n","      x_dists.append(0)\n","      y_dists.append(0)\n","    else:\n","      # get center of bb\n","      #center_x_bb = (box_pos[0] + box_pos[2]) / 2\n","      #center_y_bb = (box_pos[1] + box_pos[3]) / 2\n","      center_x_bb = box_pos[0]\n","      center_y_bb = box_pos[1]\n","      # calculate distances\n","      x_dists.append(abs(center_x-center_x_bb))\n","      y_dists.append(abs(center_y-center_y_bb))\n","\n","\n","  video_corrected = np.zeros((len(video),\n","                              int(height + max(y_dists)*2),\n","                              int(width + max(x_dists)*2),\n","                              3), dtype=int)\n","  ############################################################################\n","\n","\n","  ############################ Align video ###################################\n","  # get coords for placement height and width. may be switched\n","  start_row = (video_corrected.shape[1] - height) // 2\n","  start_col = (video_corrected.shape[2] - width) // 2\n","\n","  for idx, frame in enumerate(tqdm(video)):\n","\n","    # get matching bb\n","    box_curr = bbs[idx]\n","\n","    # If there is no information on fruit, color the frame black (skip iter)\n","    if np.isnan(box_curr).any():\n","      continue\n","      # frame[:] = 0\n","      # frame = np.zeros(frame.shape)\n","    else:\n","      # get center of bb\n","      #center_x_bb = (box_curr[0] + box_curr[2]) / 2\n","      #center_y_bb = (box_curr[1] + box_curr[3]) / 2\n","      center_x_bb = box_curr[0]\n","      center_y_bb = box_curr[1]\n","\n","      # get offset of center\n","      # pos if bounding box is to right of center, else negative\n","      x_offset = int(center_x_bb - center_x)\n","      # pos if bounding box is below center, else negative\n","      y_offset = int(center_y_bb - center_y)\n","\n","      #!coordinates until here are for old video\n","\n","      #get fitting indices for new video\n","      fixed_start_row = start_row - y_offset\n","      fixed_start_col = start_col - x_offset\n","\n","      fixed_end_row = fixed_start_row + height\n","      fixed_end_col = fixed_start_col + width\n","\n","      #Checkup\n","      if((fixed_start_row or\n","          fixed_start_col or\n","          fixed_end_row or\n","          fixed_end_col) < 0):\n","          print(\"Negative Index!\")\n","\n","      if (idx == 0):\n","          print(\"fixed_start_row:\",fixed_start_row)\n","          print(\"fixed_start_col:\",fixed_start_col)\n","\n","          print(video.shape)\n","          print(video_corrected.shape)\n","          print(fixed_end_row - fixed_start_row)\n","          print(fixed_end_col - fixed_start_col)\n","          print(frame.shape)\n","\n","      # Save centered + corrected in new video\n","      video_corrected[idx][fixed_start_row:fixed_end_row,\n","                          fixed_start_col:fixed_end_col] = frame\n","  ##########################################################################\n","\n","\n","  ############################ Save video ##################################\n","  video_corrected = np.uint8(video_corrected)\n","\n","  height_new = int(video_corrected.shape[1])\n","  width_new = int(video_corrected.shape[2])\n","\n","  fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n","  out = cv2.VideoWriter(to_path[:-4]+'_corrected.mp4', fourcc, FPS, (width_new, height_new), True)\n","  for idx in range(len(video)):\n","      out.write(video_corrected[idx])\n","  out.release()\n","  ##########################################################################"],"metadata":{"id":"KjTnqYuouFnu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Input"],"metadata":{"id":"n1OVMgLRiBSf"}},{"cell_type":"markdown","source":["1. Get the bounding boxes of all objects in each raw video and filter for the hand and target fruit bounding boxes.\n","2. Center the target fruit for each video (TARGET.mp4) and save the corrected videos to another folder (Input X).\n","3. Get the bounding boxes for the hand in the centered videos (Labels Y).\n","\n","The bounding boxes of the hand and target fruit in the corrected videos are the inputs X for the transformer training.\n","The bounding boxes of the hand in the corrected videos are the corresponding labels Y for the transformer training."],"metadata":{"id":"rkb5TAAFGKWp"}},{"cell_type":"code","source":["model = ultralytics.YOLO('yolov8n.pt')\n","folderpath = '/content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/'\n","labelpath = '/content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/'\n","\n","folder = [f for f in os.listdir(folderpath) if os.path.isfile(os.path.join(folderpath, f))]\n","input = np.zeros((1, 10)) # filename, frame, x_center_f, y_center_f, bbwidth_f, bbheight_f, x_center_h, y_center_h, bbwidth_h, bbheight_h (raw)\n","labels = np.zeros((1, 6)) # filename, frame, x_center_h, y_center_h, bbwidth_h, bbheight_h (corrected)\n","\n","\n","# Iterate through every video file in the folder\n","for i, video in enumerate(folder):\n","\n","  print(f\"Video {i+1}/{len(folder)}: {video}\\n\")\n","\n","  # Get length of input array (number of frames)\n","  cap = cv2.VideoCapture(folderpath+video)\n","  frameCount = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","  cap.release()\n","\n","\n","  # 1. Get all bbs of this video\n","  # (x_center, y_center, bbwidth, bbheight, class, trackerID, frame, filename)\n","  bbs, classes = VideoBBs(folderpath+video)\n","  video_count = np.repeat(i, len(bbs)).reshape((len(bbs),1))\n","  bbs = np.concatenate((video_count, bbs), axis=1)\n","\n","\n","  # 2. Filter for hand and target fruit by class and trackingID\n","  # Get the target class to filter for as number\n","  if '.mp4' in video:\n","    # returns the string name without '00.mp4' ending (could add try-catch)\n","    target_class = video[:-6]\n","\n","  # Get class number from lookup table\n","  target_class = list(classes.keys())[list(classes.values()).index(target_class)]\n","  hand_class = list(classes.keys())[list(classes.values()).index('person')]\n","\n","  # Filter data\n","  target_bbs = bbs[(bbs[:, 2] == target_class)]\n","  hand_bbs = bbs[(bbs[:, 2] == hand_class)]\n","\n","  # To Do: Use trackerID to track the same object\n","  # -> could be added later on, as we only use one object per trial?\n","  # -> but if we have detection of more than one target fruit, it breaks something\n","  # because it will try to calculate positions from more than one bb per frame.\n","  # problem so far: if detection ends for one frame, a new trackerID is assigned\n","  # -> for this approach to work we would have to compare the position of the\n","  # last tracked trackerID to each object with newly assigned trackerID and\n","  # take the closest one, and interpolate position if there are no new trackerIDs detected.\n","  # for now, we leave it out: remove class and trackingID\n","  target_bbs = target_bbs[:, [0,1,3,4,5,6]]\n","  hand_bbs = hand_bbs[:, [0,1,3,4,5,6]]\n","\n","\n","  # 3. Interpolation: take last known bounding box positions --> input X\n","  # (x_center_fruit, y_center_fruit, bbwidth_fruit, bbheight_fruit, class, trackerID, frame, filename, x_center_hand, y_center_hand, bbwidth_hand, bbheight_hand)\n","  vid_input = np.zeros((frameCount, 10))\n","  vid_input[:] = np.nan # use as 'no information' instead of nan, because nan is a string\n","\n","  for frame in range(len(vid_input)):\n","      # get information on objects\n","      target_information = target_bbs[(target_bbs[:, 1] == frame), :]\n","      hand_information = hand_bbs[(hand_bbs[:, 1] == frame), 2:]\n","\n","      # fill information for fruit\n","      if (frame in target_bbs[:, 1]) & (target_information.shape[0] == 1): # col 1 is frames\n","        vid_input[frame, :6] = target_information\n","      else:\n","        # if we have a frame without information on the object (object was not detected)\n","        # we take the information from the last row if it was not the first frame\n","        if frame == 0:\n","          vid_input[frame, 1] = frame\n","          vid_input[frame, 0] = i\n","          continue\n","        else:\n","          # interpolation method: last known information\n","          # (should be replaced by positional interpolation)\n","          vid_input[frame, :6] = vid_input[frame-1, :6]\n","\n","      # fill information for hand\n","      if (frame in hand_bbs[:, 1]) & (hand_information.shape[0] == 1): # col 1 is frames\n","        \"\"\"\n","        Fails in the line below if we have more than one detection for the same object/class per frame.\n","        current workaround: take last known information (like current interpolation method)\n","        -> better option: compare to last known information and take closer one\n","        \"\"\"\n","        vid_input[frame, 6:] = hand_information\n","      else:\n","        # if we have a frame without information on the object (object was not detected)\n","        # we take the information from the last row if it was not the first frame\n","        if frame == 0:\n","          vid_input[frame, 1] = frame\n","          vid_input[frame, 0] = i\n","          continue\n","        else:\n","          vid_input[frame, 6:] = vid_input[frame-1, 6:]\n","\n","      vid_input[frame, 1] = frame\n","      vid_input[frame, 0] = i\n","\n","\n","  # 4. Align: Center on the correct bounding boxes of the target fruit\n","  Align(folderpath+video, labelpath+video, vid_input[:, 2:6])\n","  bbs_corrected, classes = VideoBBs(labelpath+video[:-4]+'_corrected.mp4')\n","  video_count = np.repeat(i, len(bbs_corrected)).reshape((len(bbs_corrected),1))\n","  bbs_corrected = np.concatenate((video_count, bbs_corrected), axis=1)\n","  hand_bbs_corrected = bbs_corrected[(bbs_corrected[:, 2] == hand_class)]\n","  hand_bbs_corrected = hand_bbs_corrected[:, [0,1,3,4,5,6]]\n","\n","\n","  # 5. Filter for hand by class and trackingID\n","  vid_labels = np.zeros((frameCount, 6))\n","  vid_labels[:] = np.nan\n","\n","  for frame in range(len(vid_labels)):\n","    # corrected hand bounding boxes: xc, yc, w, h\n","    hand_information = hand_bbs_corrected[(hand_bbs_corrected[:, 1] == frame)]\n","\n","    # fill information\n","    if (frame in hand_bbs_corrected[:, 1]) & (hand_information.shape[0] == 1):\n","      vid_labels[frame] = hand_information\n","    else:\n","      # if we have a frame without information on the object (object was not detected)\n","      # we take the information from the last row if it was not the first frame\n","      if frame == 0:\n","        vid_labels[frame, 1] = frame\n","        vid_labels[frame, 0] = i\n","        continue\n","      else:\n","        vid_labels[frame, 2:] = vid_labels[frame-1, 2:]\n","\n","    vid_labels[frame, 1] = frame\n","    vid_labels[frame, 0] = i\n","\n","\n","  # 6. Bind input X together and bind labels Y together\n","  input = np.concatenate((input, vid_input), axis=0)\n","  labels = np.concatenate((labels, vid_labels), axis=0)\n","\n","\n","# Input X and labels Y (remove first row because it is random init)\n","input = input[1:]\n","labels = labels[1:]\n","\n","start_frame = 0\n","for i, frame in enumerate(input):\n","  if np.isnan(frame).any():\n","    start_frame = i+1\n","  else:\n","    break\n","\n","# only keep rows with information on both, hand and target\n","input = input[start_frame:]\n","labels = labels[start_frame:]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fiJg0H1RXt_v","outputId":"e5f8384a-cf9f-4d4e-ac1f-ccac9ad75588","executionInfo":{"status":"ok","timestamp":1687346215757,"user_tz":-120,"elapsed":18738,"user":{"displayName":"Florian P√§tzold","userId":"14560267868897327267"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Video 1/1: banana02.mp4\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n","\n","    WARNING ‚ö†Ô∏è stream/video/webcam/dir predict source will accumulate results in RAM unless `stream=True` is passed,\n","    causing potential out-of-memory errors for large sources or long-running streams/videos.\n","\n","    Usage:\n","        results = model(source=..., stream=True)  # generator of Results objects\n","        for r in results:\n","            boxes = r.boxes  # Boxes object for bbox outputs\n","            masks = r.masks  # Masks object for segment masks outputs\n","            probs = r.probs  # Class probabilities for classification outputs\n","\n","video 1/1 (1/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 orange, 1 bed, 1 tv, 1 laptop, 1 keyboard, 1 cell phone, 7.6ms\n","video 1/1 (2/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 person, 1 orange, 1 bed, 1 tv, 1 laptop, 1 keyboard, 8.2ms\n","video 1/1 (3/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 orange, 1 bed, 1 tv, 1 laptop, 1 keyboard, 9.5ms\n","video 1/1 (4/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 orange, 1 keyboard, 6.7ms\n","video 1/1 (5/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 orange, 1 keyboard, 8.1ms\n","video 1/1 (6/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 orange, 1 keyboard, 8.7ms\n","video 1/1 (7/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 orange, 1 laptop, 1 keyboard, 2 cell phones, 9.1ms\n","video 1/1 (8/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 orange, 1 tv, 1 laptop, 1 keyboard, 2 cell phones, 1 book, 6.7ms\n","video 1/1 (9/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 orange, 1 tv, 1 laptop, 1 keyboard, 2 cell phones, 1 book, 9.7ms\n","video 1/1 (10/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 person, 1 orange, 2 laptops, 2 cell phones, 2 books, 8.5ms\n","video 1/1 (11/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 person, 1 apple, 1 orange, 1 tv, 2 laptops, 1 cell phone, 10.8ms\n","video 1/1 (12/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 apple, 1 orange, 1 tv, 1 laptop, 1 keyboard, 1 cell phone, 2 books, 9.3ms\n","video 1/1 (13/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 person, 1 apple, 1 orange, 1 tv, 1 laptop, 1 cell phone, 1 microwave, 7.7ms\n","video 1/1 (14/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 apple, 1 orange, 1 tv, 1 laptop, 1 cell phone, 1 microwave, 15.6ms\n","video 1/1 (15/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 person, 1 banana, 1 apple, 1 keyboard, 2 cell phones, 1 book, 9.6ms\n","video 1/1 (16/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 person, 1 banana, 1 orange, 1 tv, 2 laptops, 1 keyboard, 1 cell phone, 9.0ms\n","video 1/1 (17/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 person, 1 banana, 1 orange, 1 tv, 2 laptops, 1 keyboard, 1 cell phone, 8.9ms\n","video 1/1 (18/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 person, 1 banana, 1 orange, 2 tvs, 2 laptops, 2 cell phones, 8.8ms\n","video 1/1 (19/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 person, 1 banana, 1 apple, 1 orange, 1 laptop, 1 cell phone, 7.5ms\n","video 1/1 (20/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 person, 1 banana, 1 apple, 1 orange, 1 tv, 1 laptop, 1 cell phone, 9.8ms\n","video 1/1 (21/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 person, 1 banana, 1 orange, 1 tv, 1 laptop, 1 keyboard, 1 cell phone, 6.4ms\n","video 1/1 (22/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 banana, 1 orange, 1 tv, 1 laptop, 1 keyboard, 1 cell phone, 11.4ms\n","video 1/1 (23/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 2 persons, 1 banana, 1 orange, 1 keyboard, 1 cell phone, 1 book, 9.1ms\n","video 1/1 (24/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 2 persons, 1 banana, 1 orange, 1 laptop, 1 keyboard, 1 cell phone, 8.9ms\n","video 1/1 (25/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 person, 1 banana, 1 orange, 1 keyboard, 1 cell phone, 9.0ms\n","video 1/1 (26/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 2 persons, 1 banana, 1 apple, 1 orange, 1 laptop, 1 keyboard, 1 cell phone, 6.9ms\n","video 1/1 (27/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 2 persons, 1 banana, 1 apple, 1 orange, 1 laptop, 1 keyboard, 1 cell phone, 9.4ms\n","video 1/1 (28/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 person, 1 banana, 1 apple, 1 orange, 1 laptop, 1 cell phone, 11.7ms\n","video 1/1 (29/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 banana, 1 apple, 1 orange, 1 tv, 1 laptop, 1 cell phone, 8.6ms\n","video 1/1 (30/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 banana, 1 apple, 1 orange, 1 tv, 1 laptop, 1 cell phone, 9.8ms\n","video 1/1 (31/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 banana, 1 apple, 1 orange, 1 tv, 1 laptop, 1 cell phone, 9.8ms\n","video 1/1 (32/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 banana, 1 apple, 1 orange, 1 tv, 1 laptop, 1 cell phone, 9.5ms\n","video 1/1 (33/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 banana, 1 orange, 1 cell phone, 8.2ms\n","video 1/1 (34/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 banana, 1 orange, 1 cell phone, 9.8ms\n","video 1/1 (35/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 banana, 1 orange, 2 tvs, 1 cell phone, 7.6ms\n","video 1/1 (36/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 banana, 1 apple, 1 orange, 2 tvs, 1 laptop, 1 cell phone, 6.6ms\n","video 1/1 (37/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 banana, 1 apple, 1 orange, 2 tvs, 1 laptop, 1 cell phone, 10.5ms\n","video 1/1 (38/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 banana, 1 orange, 1 laptop, 1 cell phone, 10.0ms\n","video 1/1 (39/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 banana, 1 apple, 1 orange, 1 tv, 1 laptop, 1 cell phone, 8.9ms\n","video 1/1 (40/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 banana, 1 apple, 1 orange, 1 tv, 1 laptop, 1 cell phone, 8.3ms\n","video 1/1 (41/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 banana, 1 apple, 1 orange, 1 tv, 1 laptop, 1 cell phone, 9.8ms\n","video 1/1 (42/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 banana, 1 apple, 1 orange, 1 tv, 2 laptops, 1 cell phone, 10.5ms\n","video 1/1 (43/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 apple, 1 orange, 1 tv, 1 laptop, 1 cell phone, 7.6ms\n","video 1/1 (44/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 apple, 1 orange, 1 tv, 1 laptop, 1 cell phone, 9.5ms\n","video 1/1 (45/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 banana, 1 apple, 1 orange, 1 laptop, 1 cell phone, 11.3ms\n","video 1/1 (46/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 banana, 1 apple, 1 orange, 1 tv, 2 laptops, 1 cell phone, 9.7ms\n","video 1/1 (47/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 banana, 1 apple, 1 orange, 1 tv, 2 laptops, 1 cell phone, 7.1ms\n","video 1/1 (48/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 banana, 1 apple, 1 orange, 1 tv, 2 laptops, 1 cell phone, 7.8ms\n","video 1/1 (49/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 banana, 1 apple, 1 orange, 1 tv, 2 laptops, 1 cell phone, 11.4ms\n","video 1/1 (50/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 orange, 1 tv, 1 laptop, 1 cell phone, 9.4ms\n","video 1/1 (51/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 apple, 1 orange, 1 tv, 1 cell phone, 11.1ms\n","video 1/1 (52/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 banana, 1 orange, 1 tv, 1 cell phone, 9.5ms\n","video 1/1 (53/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 banana, 1 apple, 1 orange, 2 tvs, 1 keyboard, 1 cell phone, 1 book, 8.0ms\n","video 1/1 (54/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 banana, 1 apple, 1 orange, 2 tvs, 1 keyboard, 1 cell phone, 9.2ms\n","video 1/1 (55/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 apple, 1 orange, 2 tvs, 1 laptop, 1 keyboard, 1 cell phone, 10.2ms\n","video 1/1 (56/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 apple, 1 orange, 2 tvs, 1 laptop, 1 keyboard, 1 cell phone, 9.0ms\n","video 1/1 (57/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 apple, 1 orange, 1 tv, 1 laptop, 1 keyboard, 1 cell phone, 11.7ms\n","video 1/1 (58/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 apple, 1 orange, 1 tv, 1 laptop, 1 keyboard, 1 cell phone, 1 book, 9.9ms\n","video 1/1 (59/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 apple, 1 orange, 1 tv, 1 laptop, 1 keyboard, 1 cell phone, 1 book, 12.6ms\n","video 1/1 (60/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 banana, 1 apple, 1 orange, 1 tv, 2 laptops, 1 keyboard, 1 cell phone, 1 book, 9.7ms\n","video 1/1 (61/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 banana, 1 apple, 1 orange, 1 tv, 2 laptops, 1 cell phone, 9.8ms\n","video 1/1 (62/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 banana, 1 orange, 1 tv, 1 laptop, 1 cell phone, 1 book, 6.9ms\n","video 1/1 (63/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 banana, 1 orange, 1 tv, 1 laptop, 1 cell phone, 9.7ms\n","video 1/1 (64/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 banana, 1 apple, 1 orange, 1 laptop, 1 cell phone, 1 book, 10.8ms\n","video 1/1 (65/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 person, 1 banana, 1 orange, 2 laptops, 1 cell phone, 9.6ms\n","video 1/1 (66/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 person, 1 banana, 1 orange, 2 laptops, 1 keyboard, 1 cell phone, 7.9ms\n","video 1/1 (67/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 person, 1 banana, 1 orange, 2 laptops, 1 keyboard, 1 cell phone, 9.4ms\n","video 1/1 (68/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 person, 1 orange, 2 laptops, 1 keyboard, 1 cell phone, 2 books, 7.5ms\n","video 1/1 (69/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 person, 1 orange, 2 laptops, 1 keyboard, 1 cell phone, 2 books, 9.2ms\n","video 1/1 (70/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 person, 1 apple, 1 orange, 2 laptops, 1 cell phone, 1 book, 6.6ms\n","video 1/1 (71/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 person, 1 apple, 1 orange, 2 laptops, 1 cell phone, 1 book, 10.6ms\n","video 1/1 (72/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 person, 1 orange, 2 laptops, 1 cell phone, 1 book, 10.8ms\n","video 1/1 (73/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 2 persons, 1 orange, 1 laptop, 1 keyboard, 1 cell phone, 1 book, 7.8ms\n","video 1/1 (74/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 cell phone, 10.0ms\n","video 1/1 (75/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 cell phone, 9.4ms\n","video 1/1 (76/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 cell phone, 10.0ms\n","video 1/1 (77/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 cell phone, 9.8ms\n","video 1/1 (78/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 cell phone, 10.9ms\n","video 1/1 (79/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 cell phone, 7.0ms\n","video 1/1 (80/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 cell phone, 9.4ms\n","video 1/1 (81/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 cell phone, 7.2ms\n","video 1/1 (82/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 person, 1 cell phone, 8.9ms\n","video 1/1 (83/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 person, 1 cell phone, 9.8ms\n","video 1/1 (84/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 person, 1 cell phone, 7.8ms\n","video 1/1 (85/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 person, 1 keyboard, 1 cell phone, 11.2ms\n","video 1/1 (86/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 person, 1 keyboard, 1 cell phone, 9.0ms\n","video 1/1 (87/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 person, 1 keyboard, 1 cell phone, 7.9ms\n","video 1/1 (88/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 person, 1 keyboard, 1 cell phone, 11.1ms\n","video 1/1 (89/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 person, 1 keyboard, 1 cell phone, 7.0ms\n","video 1/1 (90/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 person, 1 keyboard, 1 cell phone, 8.7ms\n","video 1/1 (91/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 person, 1 keyboard, 1 cell phone, 8.2ms\n","video 1/1 (92/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 person, 1 keyboard, 1 cell phone, 9.6ms\n","video 1/1 (93/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 person, 1 keyboard, 1 cell phone, 6.5ms\n","video 1/1 (94/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 person, 1 keyboard, 1 cell phone, 10.2ms\n","video 1/1 (95/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 person, 1 keyboard, 1 cell phone, 10.8ms\n","video 1/1 (96/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 person, 1 keyboard, 1 cell phone, 10.6ms\n","video 1/1 (97/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 person, 1 keyboard, 1 cell phone, 9.2ms\n","video 1/1 (98/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 person, 1 keyboard, 1 cell phone, 6.6ms\n","video 1/1 (99/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 person, 1 keyboard, 1 cell phone, 10.0ms\n","video 1/1 (100/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 person, 1 keyboard, 1 cell phone, 10.8ms\n","video 1/1 (101/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 person, 1 keyboard, 1 cell phone, 9.7ms\n","video 1/1 (102/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 person, 1 keyboard, 1 cell phone, 8.7ms\n","video 1/1 (103/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 person, 1 keyboard, 1 cell phone, 8.9ms\n","video 1/1 (104/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 person, 1 keyboard, 1 cell phone, 7.8ms\n","video 1/1 (105/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 person, 1 orange, 1 keyboard, 1 cell phone, 8.5ms\n","video 1/1 (106/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 person, 1 orange, 1 keyboard, 1 cell phone, 9.1ms\n","video 1/1 (107/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 person, 1 orange, 1 keyboard, 1 cell phone, 9.2ms\n","video 1/1 (108/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 person, 1 orange, 1 keyboard, 1 cell phone, 9.4ms\n","video 1/1 (109/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 person, 1 orange, 1 keyboard, 1 cell phone, 10.4ms\n","video 1/1 (110/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 person, 1 orange, 1 keyboard, 1 cell phone, 9.2ms\n","video 1/1 (111/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 person, 1 orange, 1 keyboard, 1 cell phone, 11.6ms\n","video 1/1 (112/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 person, 1 orange, 1 keyboard, 1 cell phone, 6.6ms\n","video 1/1 (113/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 person, 1 orange, 1 keyboard, 1 cell phone, 10.4ms\n","video 1/1 (114/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 person, 1 orange, 1 keyboard, 1 cell phone, 8.1ms\n","video 1/1 (115/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 person, 1 orange, 1 keyboard, 1 cell phone, 9.5ms\n","video 1/1 (116/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/0 Trials/banana02.mp4: 384x640 1 person, 1 orange, 1 keyboard, 1 cell phone, 6.9ms\n","Speed: 3.2ms preprocess, 9.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 116/116 [00:03<00:00, 32.53it/s]\n","\n","\n","    WARNING ‚ö†Ô∏è stream/video/webcam/dir predict source will accumulate results in RAM unless `stream=True` is passed,\n","    causing potential out-of-memory errors for large sources or long-running streams/videos.\n","\n","    Usage:\n","        results = model(source=..., stream=True)  # generator of Results objects\n","        for r in results:\n","            boxes = r.boxes  # Boxes object for bbox outputs\n","            masks = r.masks  # Masks object for segment masks outputs\n","            probs = r.probs  # Class probabilities for classification outputs\n","\n","video 1/1 (1/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 (no detections), 8.3ms\n","video 1/1 (2/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 (no detections), 7.5ms\n","video 1/1 (3/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 (no detections), 6.9ms\n","video 1/1 (4/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 (no detections), 6.7ms\n","video 1/1 (5/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 (no detections), 6.8ms\n","video 1/1 (6/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 (no detections), 7.3ms\n","video 1/1 (7/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 (no detections), 6.8ms\n","video 1/1 (8/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 (no detections), 7.1ms\n","video 1/1 (9/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 (no detections), 6.8ms\n","video 1/1 (10/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 (no detections), 7.0ms\n","video 1/1 (11/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 (no detections), 7.5ms\n","video 1/1 (12/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 (no detections), 6.8ms\n","video 1/1 (13/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 (no detections), 6.6ms\n","video 1/1 (14/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 (no detections), 6.9ms\n","video 1/1 (15/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 1 keyboard, 2 cell phones, 1 book, 6.9ms\n","video 1/1 (16/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 2 cell phones, 1 book, 7.8ms\n","video 1/1 (17/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 2 cell phones, 1 book, 6.7ms\n","video 1/1 (18/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 1 keyboard, 2 cell phones, 1 book, 9.2ms\n","video 1/1 (19/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 1 tv, 2 cell phones, 1 book, 6.7ms\n","video 1/1 (20/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 1 tv, 2 cell phones, 1 book, 7.5ms\n","video 1/1 (21/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 1 tv, 2 cell phones, 1 book, 7.9ms\n","video 1/1 (22/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 1 tv, 2 cell phones, 1 book, 9.0ms\n","video 1/1 (23/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 2 persons, 1 tv, 1 cell phone, 1 book, 10.1ms\n","video 1/1 (24/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 2 persons, 1 tv, 1 cell phone, 7.3ms\n","video 1/1 (25/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 2 persons, 2 cell phones, 1 book, 6.4ms\n","video 1/1 (26/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 2 persons, 1 keyboard, 2 cell phones, 1 book, 8.5ms\n","video 1/1 (27/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 2 persons, 1 tv, 1 keyboard, 2 cell phones, 1 book, 7.0ms\n","video 1/1 (28/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 2 persons, 1 tv, 1 keyboard, 2 cell phones, 1 book, 8.6ms\n","video 1/1 (29/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 2 persons, 1 tv, 1 keyboard, 1 cell phone, 1 book, 6.4ms\n","video 1/1 (30/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 1 tv, 1 keyboard, 2 cell phones, 1 book, 6.6ms\n","video 1/1 (31/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 1 tv, 1 keyboard, 2 cell phones, 1 book, 11.0ms\n","video 1/1 (32/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 2 persons, 1 tv, 1 keyboard, 1 cell phone, 1 book, 27.4ms\n","video 1/1 (33/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 1 tv, 1 keyboard, 2 cell phones, 1 book, 17.7ms\n","video 1/1 (34/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 2 persons, 1 tv, 1 keyboard, 2 cell phones, 1 book, 11.7ms\n","video 1/1 (35/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 1 tv, 2 cell phones, 10.1ms\n","video 1/1 (36/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 2 persons, 1 tv, 1 cell phone, 1 book, 27.8ms\n","video 1/1 (37/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 2 persons, 1 tv, 1 cell phone, 1 book, 19.1ms\n","video 1/1 (38/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 1 tv, 1 keyboard, 2 cell phones, 1 book, 10.5ms\n","video 1/1 (39/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 1 tv, 2 cell phones, 10.8ms\n","video 1/1 (40/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 1 tv, 1 cell phone, 1 book, 10.8ms\n","video 1/1 (41/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 tv, 2 cell phones, 10.2ms\n","video 1/1 (42/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 1 tv, 1 cell phone, 1 book, 15.5ms\n","video 1/1 (43/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 1 tv, 1 cell phone, 1 book, 15.7ms\n","video 1/1 (44/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 2 tvs, 1 cell phone, 1 book, 25.3ms\n","video 1/1 (45/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 1 tv, 2 cell phones, 1 book, 27.1ms\n","video 1/1 (46/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 1 tv, 2 cell phones, 1 book, 12.1ms\n","video 1/1 (47/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 1 tv, 2 cell phones, 1 book, 10.9ms\n","video 1/1 (48/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 1 tv, 1 cell phone, 1 book, 10.7ms\n","video 1/1 (49/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 1 cell phone, 1 book, 11.6ms\n","video 1/1 (50/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 2 cell phones, 1 book, 9.5ms\n","video 1/1 (51/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 tv, 1 keyboard, 2 cell phones, 1 book, 11.0ms\n","video 1/1 (52/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 tv, 1 keyboard, 2 cell phones, 1 book, 11.3ms\n","video 1/1 (53/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 tv, 1 keyboard, 2 cell phones, 1 book, 11.8ms\n","video 1/1 (54/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 tv, 2 cell phones, 1 book, 9.9ms\n","video 1/1 (55/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 tv, 1 keyboard, 2 cell phones, 1 book, 11.2ms\n","video 1/1 (56/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 tv, 1 keyboard, 2 cell phones, 1 book, 20.5ms\n","video 1/1 (57/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 2 tvs, 1 keyboard, 1 book, 10.3ms\n","video 1/1 (58/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 2 tvs, 1 keyboard, 1 book, 11.9ms\n","video 1/1 (59/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 2 tvs, 1 keyboard, 1 cell phone, 1 book, 11.7ms\n","video 1/1 (60/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 1 orange, 1 tv, 1 cell phone, 21.8ms\n","video 1/1 (61/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 1 orange, 1 tv, 1 cell phone, 12.6ms\n","video 1/1 (62/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 2 cell phones, 11.2ms\n","video 1/1 (63/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 2 cell phones, 11.2ms\n","video 1/1 (64/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 1 tv, 2 cell phones, 19.1ms\n","video 1/1 (65/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 1 tv, 1 laptop, 2 cell phones, 24.5ms\n","video 1/1 (66/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 2 tvs, 1 cell phone, 28.8ms\n","video 1/1 (67/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 2 tvs, 1 cell phone, 35.4ms\n","video 1/1 (68/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 3 tvs, 1 laptop, 1 cell phone, 26.9ms\n","video 1/1 (69/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 3 tvs, 1 laptop, 1 cell phone, 40.5ms\n","video 1/1 (70/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 1 orange, 2 tvs, 4 laptops, 10.1ms\n","video 1/1 (71/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 1 orange, 2 tvs, 4 laptops, 23.6ms\n","video 1/1 (72/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 1 banana, 1 orange, 2 tvs, 4 laptops, 11.5ms\n","video 1/1 (73/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 2 tvs, 1 laptop, 23.0ms\n","video 1/1 (74/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 2 persons, 2 tvs, 1 laptop, 14.6ms\n","video 1/1 (75/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 1 banana, 1 orange, 1 tv, 3 laptops, 10.7ms\n","video 1/1 (76/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 2 persons, 1 banana, 1 orange, 3 laptops, 1 keyboard, 1 cell phone, 9.4ms\n","video 1/1 (77/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 2 persons, 1 banana, 1 orange, 1 tv, 2 laptops, 1 keyboard, 10.3ms\n","video 1/1 (78/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 11.7ms\n","video 1/1 (79/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 1 laptop, 11.3ms\n","video 1/1 (80/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 1 laptop, 11.2ms\n","video 1/1 (81/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 1 laptop, 11.5ms\n","video 1/1 (82/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 1 laptop, 11.8ms\n","video 1/1 (83/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 1 laptop, 1 cell phone, 12.8ms\n","video 1/1 (84/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 1 laptop, 1 cell phone, 12.2ms\n","video 1/1 (85/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 1 laptop, 1 cell phone, 14.3ms\n","video 1/1 (86/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 1 laptop, 1 cell phone, 10.4ms\n","video 1/1 (87/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 1 laptop, 1 cell phone, 11.5ms\n","video 1/1 (88/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 1 laptop, 1 cell phone, 10.7ms\n","video 1/1 (89/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 1 laptop, 1 cell phone, 15.2ms\n","video 1/1 (90/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 1 laptop, 1 cell phone, 31.4ms\n","video 1/1 (91/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 1 laptop, 1 cell phone, 10.9ms\n","video 1/1 (92/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 1 laptop, 1 cell phone, 19.0ms\n","video 1/1 (93/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 1 laptop, 1 cell phone, 19.2ms\n","video 1/1 (94/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 1 laptop, 1 cell phone, 11.8ms\n","video 1/1 (95/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 1 laptop, 1 cell phone, 11.4ms\n","video 1/1 (96/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 1 laptop, 1 cell phone, 11.0ms\n","video 1/1 (97/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 1 laptop, 1 cell phone, 16.1ms\n","video 1/1 (98/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 1 laptop, 1 cell phone, 10.1ms\n","video 1/1 (99/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 1 laptop, 1 cell phone, 21.1ms\n","video 1/1 (100/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 1 laptop, 1 cell phone, 12.0ms\n","video 1/1 (101/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 1 laptop, 1 cell phone, 15.2ms\n","video 1/1 (102/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 1 laptop, 1 cell phone, 15.1ms\n","video 1/1 (103/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 1 laptop, 1 cell phone, 9.8ms\n","video 1/1 (104/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 1 laptop, 1 cell phone, 12.6ms\n","video 1/1 (105/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 1 laptop, 1 cell phone, 37.7ms\n","video 1/1 (106/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 1 laptop, 1 cell phone, 9.8ms\n","video 1/1 (107/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 1 laptop, 1 cell phone, 12.6ms\n","video 1/1 (108/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 1 laptop, 1 cell phone, 14.5ms\n","video 1/1 (109/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 1 laptop, 1 cell phone, 10.5ms\n","video 1/1 (110/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 2 laptops, 11.2ms\n","video 1/1 (111/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 1 laptop, 1 cell phone, 11.3ms\n","video 1/1 (112/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 1 laptop, 1 cell phone, 32.2ms\n","video 1/1 (113/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 1 laptop, 1 cell phone, 11.1ms\n","video 1/1 (114/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 1 laptop, 1 cell phone, 10.7ms\n","video 1/1 (115/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 1 laptop, 1 cell phone, 9.6ms\n","video 1/1 (116/116) /content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/1 Labels/banana02_corrected.mp4: 320x640 1 person, 1 laptop, 1 cell phone, 10.0ms\n","Speed: 3.8ms preprocess, 13.2ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n"]}]},{"cell_type":"code","source":["print(input.shape)\n","print(input[:50])\n","print()\n","print(labels.shape)\n","print(labels[:50])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K35eYeyMa85K","executionInfo":{"status":"ok","timestamp":1687345880791,"user_tz":-120,"elapsed":439,"user":{"displayName":"Florian P√§tzold","userId":"14560267868897327267"}},"outputId":"0543b052-fc1a-4897-9f1b-f7fcfd6b8aca"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(116, 10)\n","[[          0           0         nan         nan         nan         nan         nan         nan         nan         nan]\n"," [          0           1         nan         nan         nan         nan        1227      1063.3      470.29      83.989]\n"," [          0           2         nan         nan         nan         nan        1227      1063.3      470.29      83.989]\n"," [          0           3         nan         nan         nan         nan        1227      1063.3      470.29      83.989]\n"," [          0           4         nan         nan         nan         nan        1227      1063.3      470.29      83.989]\n"," [          0           5         nan         nan         nan         nan        1227      1063.3      470.29      83.989]\n"," [          0           6         nan         nan         nan         nan        1227      1063.3      470.29      83.989]\n"," [          0           7         nan         nan         nan         nan        1227      1063.3      470.29      83.989]\n"," [          0           8         nan         nan         nan         nan        1227      1063.3      470.29      83.989]\n"," [          0           9         nan         nan         nan         nan      1232.1      1068.7      463.63      68.395]\n"," [          0          10         nan         nan         nan         nan      1231.5      1068.9      465.77      69.396]\n"," [          0          11         nan         nan         nan         nan      1231.5      1068.9      465.77      69.396]\n"," [          0          12         nan         nan         nan         nan      1233.7      1068.5      462.86      70.936]\n"," [          0          13         nan         nan         nan         nan      1233.7      1068.5      462.86      70.936]\n"," [          0          14      1244.9      580.91      225.45       167.3      1224.4      1065.4      491.22      77.426]\n"," [          0          15      1229.4      574.66      213.52       170.9      1227.6      1053.7      518.02       98.32]\n"," [          0          16      1229.3      574.64      213.42      171.04      1227.7      1053.5      518.36      98.593]\n"," [          0          17      1229.7      574.53      213.18      171.12      1226.7      1052.6      515.19      99.612]\n"," [          0          18      1228.1       572.9      217.46      170.94      1226.2      1051.2       517.4      103.91]\n"," [          0          19      1228.3      572.87      217.73      170.68      1225.2      1050.8      515.92      103.99]\n"," [          0          20      1225.5      569.47      221.74      171.87      1230.5      1051.2      513.28      104.86]\n"," [          0          21      1225.4      569.43      221.53       171.8      1230.5      1051.2      513.28      104.86]\n"," [          0          22      1225.6      565.45      223.55      171.45      1230.5      1051.2      513.28      104.86]\n"," [          0          23      1225.5      563.33      224.82      170.19      1230.5      1051.2      513.28      104.86]\n"," [          0          24      1226.6      563.52      224.13      170.36      1286.9        1051      626.18      105.29]\n"," [          0          25      1228.1      563.58      220.95      169.24      1286.9        1051      626.18      105.29]\n"," [          0          26      1228.2      563.54      220.92      169.17      1286.9        1051      626.18      105.29]\n"," [          0          27      1229.6      565.91      217.72      169.05      1232.5      1043.6      522.95      125.85]\n"," [          0          28      1230.8      569.51      216.62      167.71      1232.5      1043.6      522.95      125.85]\n"," [          0          29      1231.2      571.95      217.21      170.29      1232.5      1043.6      522.95      125.85]\n"," [          0          30      1231.1      571.99      217.55      170.43      1232.5      1043.6      522.95      125.85]\n"," [          0          31      1231.4      572.36       216.8      170.85      1232.5      1043.6      522.95      125.85]\n"," [          0          32      1233.5      573.94      211.84      169.73      1232.5      1043.6      522.95      125.85]\n"," [          0          33      1233.3      573.91      211.57      169.66      1232.5      1043.6      522.95      125.85]\n"," [          0          34      1240.9      573.11      225.25      174.87      1232.5      1043.6      522.95      125.85]\n"," [          0          35      1240.1      572.94      225.33      175.36      1232.5      1043.6      522.95      125.85]\n"," [          0          36      1240.1      572.97      225.21       175.4      1232.5      1043.6      522.95      125.85]\n"," [          0          37      1232.4       575.1      211.88       170.5      1232.5      1043.6      522.95      125.85]\n"," [          0          38      1241.6      575.55      223.05      173.61      1232.5      1043.6      522.95      125.85]\n"," [          0          39      1234.3      576.97      206.65      170.12      1232.5      1043.6      522.95      125.85]\n"," [          0          40      1242.9       576.1      223.93      172.28      1232.5      1043.6      522.95      125.85]\n"," [          0          41      1234.6      577.31      206.89      169.62      1232.5      1043.6      522.95      125.85]\n"," [          0          42      1234.6      577.31      206.89      169.62      1232.5      1043.6      522.95      125.85]\n"," [          0          43      1234.6      577.31      206.89      169.62      1232.5      1043.6      522.95      125.85]\n"," [          0          44      1243.3      575.26      223.13      174.34      1232.5      1043.6      522.95      125.85]\n"," [          0          45        1243      575.37      223.64      173.32      1232.5      1043.6      522.95      125.85]\n"," [          0          46      1234.9      577.53      207.81      169.31      1232.5      1043.6      522.95      125.85]\n"," [          0          47      1234.9      577.54      207.85      169.28      1232.5      1043.6      522.95      125.85]\n"," [          0          48      1234.9      577.43      207.31      169.55      1232.5      1043.6      522.95      125.85]\n"," [          0          49      1234.9      577.43      207.31      169.55      1232.5      1043.6      522.95      125.85]]\n","\n","(116, 6)\n","[[          0           0           0           0           0           0]\n"," [          0           1           0           0           0           0]\n"," [          0           2           0           0           0           0]\n"," [          0           3           0           0           0           0]\n"," [          0           4           0           0           0           0]\n"," [          0           5           0           0           0           0]\n"," [          0           6           0           0           0           0]\n"," [          0           7           0           0           0           0]\n"," [          0           8           0           0           0           0]\n"," [          0           9           0           0           0           0]\n"," [          0          10           0           0           0           0]\n"," [          0          11           0           0           0           0]\n"," [          0          12           0           0           0           0]\n"," [          0          13           0           0           0           0]\n"," [          0          14      1233.5      1063.3      488.59      97.768]\n"," [          0          15      1246.5      1064.8      499.96       101.5]\n"," [          0          16      1246.9      1064.9      500.95      101.12]\n"," [          0          17      1241.6      1067.5      493.53      94.452]\n"," [          0          18      1237.3      1065.1      516.29      112.98]\n"," [          0          19      1237.2      1065.6      516.64      113.02]\n"," [          0          20      1249.4      1064.9      504.49      116.84]\n"," [          0          21        1249      1065.6      504.26       115.3]\n"," [          0          22        1249      1065.6      504.26       115.3]\n"," [          0          23        1249      1065.6      504.26       115.3]\n"," [          0          24        1249      1065.6      504.26       115.3]\n"," [          0          25        1249      1065.6      504.26       115.3]\n"," [          0          26        1249      1065.6      504.26       115.3]\n"," [          0          27        1249      1065.6      504.26       115.3]\n"," [          0          28        1249      1065.6      504.26       115.3]\n"," [          0          29      1245.3      1061.6      501.35      119.45]\n"," [          0          30      1250.6      1061.4      510.79      117.89]\n"," [          0          31      1250.6      1061.4      510.79      117.89]\n"," [          0          32      1244.1      1061.8      507.47      118.81]\n"," [          0          33      1244.1      1061.8      507.47      118.81]\n"," [          0          34        1256      1062.9      550.58      116.06]\n"," [          0          35        1256      1062.9      550.58      116.06]\n"," [          0          36        1256      1062.9      550.58      116.06]\n"," [          0          37      1258.9      1063.1      506.88      102.51]\n"," [          0          38        1242      1059.5      484.38      110.25]\n"," [          0          39      1252.5      1062.6      474.14      101.66]\n"," [          0          40      1252.5      1062.6      474.14      101.66]\n"," [          0          41      1249.4      1063.6      476.32      99.912]\n"," [          0          42      1251.1      1063.4      468.23      99.814]\n"," [          0          43      1251.6      1063.2      466.27      99.898]\n"," [          0          44      1238.6        1061      472.17      105.61]\n"," [          0          45      1238.8      1061.8      472.71      104.55]\n"," [          0          46      1251.2      1060.8      466.22      105.49]\n"," [          0          47      1251.1        1061      466.64      105.04]\n"," [          0          48      1251.4      1060.5      464.45      105.55]\n"," [          0          49      1250.7      1061.5      467.16      103.87]]\n"]}]},{"cell_type":"markdown","source":["## Model"],"metadata":{"id":"tHmhuucQ4QVr"}},{"cell_type":"markdown","source":["### Positional Encoding"],"metadata":{"id":"S5D7ySBZZOtr"}},{"cell_type":"code","source":["#display.Image('/content/drive/MyDrive/Studium/Semester M2/Study Project: Grasping/Media/pos_encoding.png', width=960, height=480)"],"metadata":{"id":"mkJPwWq93m8U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# https://www.youtube.com/watch?v=ZMxVe-HK174\n","\"\"\"\n","def PositionalEncoding(dims, max_seq_length):\n","    even_i = np.arange(0, dims, 2, dtype=float)\n","    denominator = tf.math.pow(10000, even_i/dims)\n","    position = np.arange(max_seq_length).reshape(max_seq_length, 1)\n","    even_PE = np.sin(position / denominator)\n","    odd_PE = np.cos(position / denominator)\n","    stacked = tf.stack([even_PE, odd_PE], 2)\n","    PE = tf.reshape(stacked, (max_seq_length, dims))\n","\n","    return PE\n","\"\"\";"],"metadata":{"id":"yP7q1og33ymW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class PositionalEncoding(tf.keras.layers.Layer):\n","    def __init__(self, position, d_model):\n","        super(PositionalEncoding, self).__init__()\n","        self.positional_encoding = self.get_positional_encoding(position, d_model)\n","\n","    def get_positional_encoding(self, sequence_length, input_dim):\n","        angle_rads = self.get_angles(tf.range(sequence_length, dtype=tf.float32)[:, tf.newaxis],\n","                                     tf.range(input_dim, dtype=tf.float32)[tf.newaxis, :],\n","                                     input_dim)\n","\n","        # Apply sine to even indices in the array\n","        sines = tf.math.sin(angle_rads[:, 0::2])\n","        # Apply cosine to odd indices in the array\n","        cosines = tf.math.cos(angle_rads[:, 1::2])\n","\n","        # Concatenate sines and cosines\n","        pos_encoding = tf.concat([sines, cosines], axis=-1)\n","        pos_encoding = pos_encoding[tf.newaxis, ...]\n","        return tf.cast(pos_encoding, dtype=tf.float32)\n","\n","    def get_angles(self, sequence_length, i, input_dim):\n","        angle_rates = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(input_dim, tf.float32))\n","        return sequence_length * angle_rates\n","\n","    def call(self, inputs):\n","        return inputs + self.positional_encoding[:, :tf.shape(inputs)[1], :]"],"metadata":{"id":"EZ1HGdOFn7XS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Encoder"],"metadata":{"id":"r2zT3EQ_4Skf"}},{"cell_type":"code","source":["# https://keras.io/examples/timeseries/timeseries_transformer_classification/\n","\n","\"\"\"\n","def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n","    # Normalization and Attention\n","    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n","    x = layers.MultiHeadAttention(\n","        key_dim=head_size, num_heads=num_heads, dropout=dropout\n","    )(x, x)\n","    x = layers.Dropout(dropout)(x)\n","    res = x + inputs\n","\n","    # Feed Forward Part\n","    x = layers.LayerNormalization(epsilon=1e-6)(res)\n","    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n","    x = layers.Dropout(dropout)(x)\n","    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n","    return x + res\n","\"\"\";"],"metadata":{"id":"UeD2m6eW4R-x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class TransformerEncoderLayer(tf.keras.layers.Layer):\n","    def __init__(self, d_model, num_heads, dff, rate=0.1):\n","        super(TransformerEncoderLayer, self).__init__()\n","\n","        self.mha = MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n","        self.ffn = keras.Sequential([\n","            Dense(dff, activation='relu'),\n","            Dense(d_model)\n","        ])\n","\n","        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n","\n","        self.dropout1 = Dropout(rate)\n","        self.dropout2 = Dropout(rate)\n","\n","    def call(self, inputs, training):\n","        attn_output = self.mha(inputs, inputs)\n","        attn_output = self.dropout1(attn_output, training=training)\n","        out1 = self.layernorm1(inputs + attn_output)\n","\n","        ffn_output = self.ffn(out1)\n","        ffn_output = self.dropout2(ffn_output, training=training)\n","        out2 = self.layernorm2(out1 + ffn_output)\n","\n","        return out2\n","\n","class TransformerEncoder(tf.keras.layers.Layer):\n","    def __init__(self, num_layers, d_model, num_heads, dff, input_dim, rate=0.1):\n","        super(TransformerEncoder, self).__init__()\n","\n","        self.d_model = d_model\n","        self.num_layers = num_layers\n","\n","        self.dense = Dense(d_model)\n","        self.enc_layers = [TransformerEncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n","\n","        self.dropout = Dropout(rate)\n","\n","    def call(self, x, training):\n","        x = self.dense(x)\n","        x = self.dropout(x, training=training)\n","\n","        for i in range(self.num_layers):\n","            x = self.enc_layers[i](x, training)\n","\n","        return x"],"metadata":{"id":"QUfYRliFoExJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Decoder"],"metadata":{"id":"pa5oe4l54apO"}},{"cell_type":"code","source":["class TransformerDecoderLayer(tf.keras.layers.Layer):\n","    def __init__(self, d_model, num_heads, dff, rate=0.1):\n","        super(TransformerDecoderLayer, self).__init__()\n","\n","        self.masked_mha1 = MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n","        self.mha2 = MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n","\n","        self.ffn = keras.Sequential([\n","            Dense(dff, activation='relu'),\n","            Dense(8) # hardcode test\n","        ])\n","\n","        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n","        self.layernorm3 = LayerNormalization(epsilon=1e-6)\n","\n","        self.dropout1 = Dropout(rate)\n","        self.dropout2 = Dropout(rate)\n","        self.dropout3 = Dropout(rate)\n","\n","    def call(self, inputs, enc_output, training, look_ahead_mask=None):\n","        attn1 = self.masked_mha1(inputs, inputs, attention_mask=look_ahead_mask)\n","        attn1 = self.dropout1(attn1, training=training)\n","        out1 = self.layernorm1(inputs + attn1)\n","\n","        attn2 = self.mha2(out1, enc_output)\n","        attn2 = self.dropout2(attn2, training=training)\n","        out2 = self.layernorm2(out1 + attn2)\n","\n","        ffn_output = self.ffn(out2)\n","        ffn_output = self.dropout3(ffn_output, training=training)\n","        out3 = self.layernorm3(out2 + ffn_output)\n","\n","        return out3\n","\n","class TransformerDecoder(tf.keras.layers.Layer):\n","    def __init__(self, num_layers, d_model, num_heads, dff, output_dim, rate=0.1):\n","        super(TransformerDecoder, self).__init__()\n","\n","        self.d_model = d_model\n","        self.num_layers = num_layers\n","\n","        self.dec_layers = [TransformerDecoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n","\n","        self.final_layer = Dense(output_dim)\n","\n","        self.dropout = Dropout(rate)\n","\n","    def call(self, x, enc_output, training, look_ahead_mask=None):\n","        for i in range(self.num_layers):\n","            x = self.dec_layers[i](x, enc_output, training, look_ahead_mask)\n","\n","        x = self.final_layer(x)\n","\n","        return x"],"metadata":{"id":"fx3_AjP54bfe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Build"],"metadata":{"id":"1YXPWKtZ477u"}},{"cell_type":"code","source":["\"\"\"\n","def build_model(\n","    input_shape,\n","    head_size,\n","    num_heads,\n","    ff_dim,\n","    num_transformer_blocks,\n","    mlp_units,\n","    dropout=0,\n","    mlp_dropout=0,\n","):\n","    inputs = keras.Input(shape=input_shape)\n","    x = inputs\n","    for _ in range(num_transformer_blocks):\n","        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n","\n","    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n","    for dim in mlp_units:\n","        x = layers.Dense(dim, activation=\"relu\")(x)\n","        x = layers.Dropout(mlp_dropout)(x)\n","    outputs = layers.Dense(n_classes, activation=\"softmax\")(x)\n","    return keras.Model(inputs, outputs)\n","\"\"\";"],"metadata":{"id":"k7z78b7C49R1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Transformer(tf.keras.Model):\n","    def __init__(self, num_layers, d_model, num_heads, dff, sequence_length, input_dim, output_dim, rate=0.1):\n","        super(Transformer, self).__init__()\n","\n","        self.positional_encoder = PositionalEncoding(sequence_length, input_dim)\n","        self.encoder = TransformerEncoder(num_layers, d_model, num_heads, dff, input_dim, rate)\n","        self.decoder = TransformerDecoder(num_layers, d_model, num_heads, dff, output_dim, rate)\n","\n","    def call(self, inp, training, look_ahead_mask=None):\n","        x = self.positional_encoder(inp)\n","        enc_output = self.encoder(x, training)\n","        dec_output = self.decoder(x, enc_output, training, look_ahead_mask)\n","\n","        return dec_output"],"metadata":{"id":"zfDS9bBhoeVU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Training"],"metadata":{"id":"veRXne1V4-wb"}},{"cell_type":"code","source":["\"\"\"\n","input_shape = x_train.shape[1:]\n","\n","model = build_model(\n","    input_shape,\n","    head_size=256,\n","    num_heads=4,\n","    ff_dim=4,\n","    num_transformer_blocks=4,\n","    mlp_units=[128],\n","    mlp_dropout=0.4,\n","    dropout=0.25,\n",")\n","\n","model.compile(\n","    loss=\"sparse_categorical_crossentropy\",\n","    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n","    metrics=[\"sparse_categorical_accuracy\"],\n",")\n","model.summary()\n","\n","callbacks = [keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n","\n","model.fit(\n","    x_train,\n","    y_train,\n","    validation_split=0.2,\n","    epochs=200,\n","    batch_size=64,\n","    callbacks=callbacks,\n",")\n","\n","model.evaluate(x_test, y_test, verbose=1)\n","\"\"\""],"metadata":{"id":"G5uBKJ2u5AFS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Prediction"],"metadata":{"id":"F8o1Fa7R538c"}},{"cell_type":"code","source":["# Define hyperparameters\n","num_layers = 4 # How often to stack encoder & decoder blocks\n","d_model = 128 # Dimensionality of the model's hidden states and the size of the model's embedding vectors\n","num_heads = 8 # Number of parallel self attention heads in the MHA layer\n","dff = 512 # Dimensionality of the feed-forward sublayer\n","sequence_length = len(input)  # length of the sequence\n","input_dim = 8  # Four coordinates each for hand and object (+ vidID + frame ?)\n","output_dim = 4  # Whats our output dimension? I would assume 4 as for the BB coordinates of the hand in each frame\n","\n","# Instantiate the Transformer model\n","transformer = Transformer(num_layers, d_model, num_heads, dff, sequence_length, input_dim, output_dim)\n","\n","# Generate dummy batched input\n","batch_size = 1\n","#input_data = tf.random.uniform((batch_size, sequence_length, input_dim))\n","input_data = input.reshape((batch_size, input.shape[0], input.shape[1]))[:, :, 2:]\n","\n","# Generate upper triangular look-ahead mask for decoder\n","look_ahead_mask = tf.linalg.band_part(tf.ones((sequence_length, sequence_length)), -1, 0)\n","\n","# Obtain predictions\n","predictions = transformer(input_data, training=False, look_ahead_mask=look_ahead_mask)"],"metadata":{"id":"2xTTYsCTmEIx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f\"Shape: {predictions.shape}, \\nPredictions: \\n{predictions}\")\n","print(len(predictions))\n","\n","# guidance vector: current - prediction"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ozw8zH5mgjBr","executionInfo":{"status":"ok","timestamp":1687346232345,"user_tz":-120,"elapsed":39,"user":{"displayName":"Florian P√§tzold","userId":"14560267868897327267"}},"outputId":"d2f158f9-ffb5-473d-c846-cb6a18528a6f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape: (1, 102, 4), \n","Predictions: \n","[[[     3.0885     0.36155     -0.7416     -1.1828]\n","  [     3.0816     0.34689    -0.71526     -1.1852]\n","  [     3.0828     0.34478    -0.71666     -1.1863]\n","  [     3.0844      0.3456    -0.71775     -1.1856]\n","  [     3.0792     0.35227    -0.71318     -1.1896]\n","  [     3.0795      0.3535    -0.71284     -1.1888]\n","  [     3.0693     0.36939    -0.70453     -1.1888]\n","  [     3.0702     0.36762    -0.70494     -1.1892]\n","  [     3.0652     0.37001    -0.70356     -1.1969]\n","  [     3.0628     0.37275    -0.70219     -1.2002]\n","  [     3.0122     0.31882    -0.62378        -1.2]\n","  [     3.0157      0.3128      -0.624     -1.1976]\n","  [     3.0168     0.30994    -0.62416     -1.1968]\n","  [      3.076     0.35157    -0.68577     -1.1863]\n","  [     3.0815      0.3472    -0.68762     -1.1828]\n","  [     3.0856     0.34341     -0.6919     -1.1796]\n","  [     3.0853     0.34469    -0.69211     -1.1792]\n","  [     3.0858     0.34468    -0.69181     -1.1773]\n","  [     3.0869     0.34457    -0.68718     -1.1741]\n","  [     3.0871     0.34399    -0.68677     -1.1743]\n","  [     3.0831     0.34241    -0.69042     -1.1884]\n","  [     3.0832      0.3424    -0.69157     -1.1887]\n","  [     3.0832     0.34294    -0.69191     -1.1883]\n","  [     3.0885     0.34466    -0.68919     -1.1724]\n","  [     3.0867     0.34109    -0.69107     -1.1833]\n","  [     3.0939     0.33735    -0.68886     -1.1672]\n","  [     3.0869     0.34001    -0.68953     -1.1852]\n","  [     3.0948     0.33532    -0.68998     -1.1694]\n","  [     3.0948     0.33558    -0.69065     -1.1696]\n","  [     3.0943     0.33699    -0.69032     -1.1689]\n","  [     3.0864      0.3396    -0.69101     -1.1854]\n","  [     3.0854      0.3414    -0.68926     -1.1856]\n","  [     3.0931     0.33803     -0.6882     -1.1695]\n","  [     3.0937     0.33678    -0.68916     -1.1707]\n","  [     3.0941     0.33607    -0.69025     -1.1709]\n","  [     3.0937     0.33729    -0.69024     -1.1704]\n","  [      3.093     0.33883    -0.68934     -1.1696]\n","  [      3.093     0.33885    -0.68814     -1.1687]\n","  [     3.0942     0.33749    -0.68957     -1.1669]\n","  [     3.0945     0.33673    -0.69016     -1.1684]\n","  [     3.0949     0.33622    -0.69123     -1.1691]\n","  [     3.0946     0.33714    -0.69156     -1.1688]\n","  [      3.094     0.33876     -0.6909      -1.168]\n","  [     3.0933     0.33971     -0.6899     -1.1675]\n","  [     3.0933     0.33921    -0.68956     -1.1679]\n","  [     3.0878     0.34322    -0.69039      -1.188]\n","  [     3.0898      0.3404    -0.69299     -1.1873]\n","  [     3.0904     0.34042    -0.69411     -1.1866]\n","  [     3.0899       0.342    -0.69357     -1.1855]\n","  [     3.0919     0.34482    -0.69462     -1.1785]\n","  [     3.0948     0.39955    -0.73578     -1.1509]\n","  [     3.0907     0.39995    -0.72657     -1.1523]\n","  [     3.0914     0.39863    -0.72791     -1.1532]\n","  [     3.0962     0.32984    -0.71409     -1.1924]\n","  [     3.0957     0.33075    -0.71358     -1.1914]\n","  [     3.0887     0.24716    -0.67564     -1.2492]\n","  [     3.0885     0.24752    -0.67475     -1.2488]\n","  [     3.0705     0.18769    -0.63694     -1.2688]\n","  [      3.071     0.18634    -0.63739     -1.2695]\n","  [     3.0713     0.18586    -0.63801     -1.2696]\n","  [     3.0713      0.1868    -0.63793     -1.2689]\n","  [     3.0707     0.18844    -0.63686     -1.2676]\n","  [     3.0704      0.1892     -0.6356     -1.2667]\n","  [     3.0705      0.1884    -0.63506     -1.2668]\n","  [     3.0711     0.18682     -0.6355     -1.2674]\n","  [     3.0716     0.18583    -0.63626     -1.2678]\n","  [     3.0717     0.18638    -0.63644     -1.2672]\n","  [     3.0293    0.078833    -0.45728     -1.2019]\n","  [     3.0261    0.083605    -0.45123     -1.1996]\n","  [     3.0165     0.05898    -0.44519     -1.2071]\n","  [     3.0123    0.052452    -0.44274     -1.2089]\n","  [     3.0012    0.040893    -0.42959     -1.2084]\n","  [      2.911     0.23459    -0.23597     -1.1054]\n","  [     2.8661     0.28903     -0.1674     -1.0771]\n","  [     2.8437     0.28021    -0.13745     -1.0735]\n","  [     2.8356     0.27492    -0.12827      -1.074]\n","  [     2.8259     0.24558    -0.11999     -1.0824]\n","  [     2.8228     0.22309    -0.12028     -1.0905]\n","  [     2.8327     0.18544    -0.13928     -1.1069]\n","  [     2.8349     0.16518    -0.14674     -1.1154]\n","  [     2.8377     0.14904    -0.15487     -1.1234]\n","  [     2.8394     0.13497    -0.16011      -1.129]\n","  [     2.8402     0.12384    -0.16372     -1.1333]\n","  [     2.8405     0.12217    -0.16523     -1.1348]\n","  [     2.8409     0.11821    -0.16684     -1.1361]\n","  [     2.8464     0.12725    -0.17086     -1.1331]\n","  [      2.848     0.12997    -0.17229     -1.1319]\n","  [     2.8513     0.13266    -0.17634     -1.1324]\n","  [     2.8506     0.12885    -0.17711     -1.1345]\n","  [     2.8541      0.1148    -0.18361     -1.1396]\n","  [     2.8556     0.10701    -0.18712     -1.1425]\n","  [     2.8505    0.095936    -0.18412     -1.1449]\n","  [     2.8501    0.095969    -0.18417     -1.1448]\n","  [     2.8485    0.096246     -0.1824     -1.1442]\n","  [     2.8555     0.10202    -0.19025     -1.1453]\n","  [     2.8591    0.098877    -0.19566      -1.148]\n","  [     2.8605    0.095189    -0.19878     -1.1503]\n","  [     2.8674    0.098226    -0.20578       -1.15]\n","  [     2.8693    0.099487    -0.20792     -1.1497]\n","  [     2.8647    0.097173    -0.20456     -1.1508]\n","  [     2.8625    0.095234    -0.20304     -1.1516]\n","  [     2.8603    0.091776    -0.20077     -1.1519]]]\n","1\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"KptG0K0dm_YJ"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"https://github.com/keras-team/keras-io/blob/master/examples/timeseries/ipynb/timeseries_classification_transformer.ipynb","timestamp":1686292503880}],"collapsed_sections":["QC1eRfTGuWyA","cJf8BcE-to4F","tHmhuucQ4QVr","S5D7ySBZZOtr","r2zT3EQ_4Skf","pa5oe4l54apO","1YXPWKtZ477u","veRXne1V4-wb","F8o1Fa7R538c"]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"}},"nbformat":4,"nbformat_minor":0}